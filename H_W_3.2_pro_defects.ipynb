{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "\n",
    "Основные цели этого задания:\n",
    "\n",
    "- Научиться строить архитектуру модели\n",
    "- Научиться распознавать факты переобучения и недообучения модели\n",
    "- Научить бороться с переобучением и недообучением модели путем варьирования ее гиперпараметров\n",
    "- Научиться применять методы регуляризации для контроля переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача:\n",
    "\n",
    "Построить модель нейронной сети, предсказывающую поломку программного обеспечения по его анонимным признакам. В данной задаче необходимо оптимизировать метрику ROC_AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from phik.report import plot_correlation_matrix\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "import shap\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План решения:\n",
    "\n",
    "1. _Загрузите данные. Проведите EDA по вашему датасету, опишите основные идеи для последующей генерации новых признаков._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_3.2.csv')\n",
    "# Переименуем названия столбцов в соответствии с PEP8\n",
    "train.columns = [re.sub('(?<!^)(?=[A-Z])|[ ]', '_', i, count=1).lower() for i in train.columns]\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возвращаем размерность\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Атрибуты\n",
    "\n",
    "1. loc: \n",
    "   - Тип: numeric\n",
    "   - Определение: Линейный подсчет строк кода по метрике МкКейба. Она используется для определения общего количества строк исходного кода в модуле.\n",
    "\n",
    "2. v(g): \n",
    "   - Тип: numeric\n",
    "   - Определение: Цикломатическая сложность по метрике МкКейба. Это количество линейных независимых путей в графе потока управления. Это помогает анализировать сложность тестирования программы.\n",
    "\n",
    "3. ev(g):\n",
    "   - Тип: numeric\n",
    "   - Определение: Сущностная сложность по метрике МкКейба. Это является производной цикломатической сложности и учитывает сложность конструкций управления.\n",
    "\n",
    "4. iv(g): \n",
    "   - Тип: numeric\n",
    "   - Определение: Дизайнерская сложность по метрике МкКейба. Она указывает на качество проектирования кода на основе структуры управления.\n",
    "\n",
    "5. n: \n",
    "   - Тип: numeric\n",
    "   - Определение: Общее количество операторов и операндов по метрике Халстеда. Эта метрика помогает оценить сложность и объем кода.\n",
    "\n",
    "6. v:\n",
    "   - Тип: numeric\n",
    "   - Определение: Объем программы по метрике Халстеда. Этот показатель помогает узнать, сколько информации содержит код.\n",
    "\n",
    "7. l: \n",
    "   - Тип: numeric\n",
    "   - Определение: Длина программы по метрике Халстеда. Это число говорит о размере программы в терминах операторов и операндов.\n",
    "\n",
    "8. d: \n",
    "   - Тип: numeric\n",
    "   - Определение: Сложность по метрике Халстеда (difficulty). Это измеряет трудности, связанные с написанием и пониманием кода.\n",
    "\n",
    "9. i: \n",
    "   - Тип: numeric\n",
    "   - Определение: Интеллект программы по метрике Халстеда. Определяет, насколько \"умным\" является код, с точки зрения работы с операторами и операндами.\n",
    "\n",
    "10. e: \n",
    "    - Тип: numeric\n",
    "    - Определение: Усилие по метрике Халстеда (effort). Этот показатель прогнозирует усилия, необходимые для понимания и поддержки программы.\n",
    "\n",
    "11. b: \n",
    "    - Тип: numeric\n",
    "    - Определение: Эта метрика может иметь различные значения в зависимости от контекста. Важно уточнить конкретное значение или описание.\n",
    "\n",
    "12. t: \n",
    "    - Тип: numeric\n",
    "    - Определение: Оценка времени разработки программы по метрике Халстеда. Предоставляет представление о времени, необходимом для работы с кодом.\n",
    "\n",
    "13. lOCode: \n",
    "    - Тип: numeric\n",
    "    - Определение: Общее количество строк кода, включая только реальные строки, но не комментарии или пустые строки.\n",
    "\n",
    "14. lOComment: \n",
    "    - Тип: numeric\n",
    "    - Определение: Количество строк комментариев в программе. Важная метрика для оценки документированности кода.\n",
    "\n",
    "15. lOBlank: \n",
    "    - Тип: numeric\n",
    "    - Определение: Количество пустых строк. Меньшее количество пустых строк может означать более компактный и, возможно, более сложный код.\n",
    "\n",
    "16. lOCodeAndComment: \n",
    "    - Тип: numeric\n",
    "    - Определение: Общее количество строк кода и комментариев вместе.\n",
    "\n",
    "17. uniq_Op: \n",
    "    - Тип: numeric\n",
    "    - Определение: Число уникальных операторов в коде, что может помочь проанализировать разнообразие использования операторов.\n",
    "\n",
    "18. uniq_Opnd: \n",
    "    - Тип: numeric\n",
    "    - Определение: Число уникальных операндов в коде. Позволяет оценить разнообразие идентификаторов и переменных.\n",
    "\n",
    "19. total_Op: \n",
    "    - Тип: numeric\n",
    "    - Определение: Общее количество операторов в коде.\n",
    "\n",
    "20. total_Opnd: \n",
    "    - Тип: numeric\n",
    "- Определение: Общее количество операндов в коде.\n",
    "\n",
    "21. branchCount: \n",
    "    - Тип: numeric\n",
    "    - Определение: Количество разветвлений в графе потока, что может помочь в понимании сложных частей кода.\n",
    "\n",
    "22. defects: \n",
    "    - Тип: {false, true}\n",
    "    - Определение: Указывает, есть ли у модуля один или несколько зарегистрированных дефектов (ошибок). Это важная метрика для оценки качества программы и ее надежности.\n",
    "\n",
    "Каждая из этих метрик предоставляет ценную информацию о качестве, сложности и читаемости программы. Они могут быть использованы для улучшения исходного кода, а также для автоматизированного анализа кода и оценки его вероятности на наличие ошибок. \n",
    "\n",
    "В контексте данной работы мы решаем задачу классификации, поскольку наш таргет <span style=\"color: orange; font-weight: bold;\">defects</span> обозначает наличие или отсутствие дефектов в модулях (значения {false, true}). Мы стремимся предсказать вероятность возникновения дефектов на основе различных метрик кода. Это позволит разработать модели, способные выявлять потенциальные проблемы еще на этапе разработки, что в свою очередь повысит качество программного обеспечения и уменьшит затраты на его исправление."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['defects'] = train['defects'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчет классов\n",
    "target_counts = train['defects'].value_counts()\n",
    "\n",
    "# Создание списка цветов. Давайте используем 2 цвета для разных классов\n",
    "colors = ['lightgreen', 'lightcoral'] + ['lightgrey'] * (len(target_counts) - 2)\n",
    "\n",
    "# Создание графика\n",
    "plt.figure(figsize=(8, 4))\n",
    "bars = plt.bar(target_counts.index, target_counts.values, color=colors)\n",
    "\n",
    "# Заголовок и подписи\n",
    "plt.title('Distribution of Target Variable', fontsize=14)\n",
    "plt.xlabel('Target Classes', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Добавляем аннотации над столбцами\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, int(yval), ha='center', va='bottom')\n",
    "\n",
    "# Показать график\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Добавляем сетку к оси Y для чтения значений\n",
    "plt.tight_layout()  # Упрощает компоновку\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- видим дисбаланс классов у таргета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчет уникальных значений:\n",
    "train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Генерация корреляционной матрицы между признаками.\n",
    "- Извлечение и сортировка корреляций признаков с переменной \"defects\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание Phi-матрицы\n",
    "phik_overview = train.phik_matrix()\n",
    "\n",
    "# Получение корреляции с целевой переменной \"defects\"\n",
    "defects_corr = phik_overview['defects'].sort_values(ascending=False)\n",
    "\n",
    "# Печать корреляций с переменной \"defects\"\n",
    "print(\"Корреляция с 'defects':\")\n",
    "print(defects_corr)\n",
    "\n",
    "# Визуализация Phi-матрицы\n",
    "def plot_correlation_matrix(matrix, x_labels, y_labels, vmin, vmax, color_map, title, fontsize_factor, figsize):\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(matrix, annot=True, fmt='.2f', cmap=color_map, vmin=vmin, vmax=vmax,\n",
    "                xticklabels=x_labels, yticklabels=y_labels, square=True, cbar_kws={\"shrink\": .8})\n",
    "    plt.title(title, fontsize=fontsize_factor * 20)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "\n",
    "# Визуализация всей Phi-матрицы\n",
    "plot_correlation_matrix(\n",
    "    phik_overview.fillna(0).values, \n",
    "    x_labels=phik_overview.columns, \n",
    "    y_labels=phik_overview.index, \n",
    "    vmin=0, vmax=1, color_map=\"coolwarm\",\n",
    "    title=r\"Correlation $\\phi_K$\", \n",
    "    fontsize_factor=1.1, figsize=(20, 14)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Обучение GradientBoostingClassifier на признаках, исключая последний столбец (целевая переменная).\n",
    "- Вычисление значений SHAP для оценки влияния каждого признака на предсказания модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "GBC_model = GradientBoostingClassifier(n_estimators=40, random_state=42)\n",
    "GBC_model.fit(train.iloc[:, :-1], train.iloc[:, -1])  # Используем все, кроме последнего столбца как признаки\n",
    "\n",
    "# Используем TreeExplainer от SHAP\n",
    "shap_test = shap.TreeExplainer(GBC_model).shap_values(train.iloc[:, :-1])  # Принимаем только признаки для SHAP\n",
    "\n",
    "# Визуализируем SHAP значения\n",
    "shap.summary_plot(shap_test, train.iloc[:, :-1], max_display=25)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Создание и обучение модели RandomForestClassifier на данных, исключая целевую переменную defects.\n",
    "- Извлечение важности признаков из обученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "model = RandomForestClassifier()\n",
    "model.fit(train.drop(columns=['defects']), train['defects'])\n",
    "\n",
    "# Получение важности признаков\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Создание DataFrame для удобного отображения\n",
    "importance_df = pd.DataFrame({'Feature': train.drop(columns=['defects']).columns, 'Importance': feature_importances})\n",
    "\n",
    "# Сортировка по важности\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Печать важностей признаков\n",
    "print(importance_df)\n",
    "\n",
    "plt.barh(train.columns[:-1], feature_importances)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Boxplot позволяет выявить выбросы и понять распределение значений в каждом признаке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))  # Изменяем размер графика\n",
    "sns.boxplot(data=train)  # Строим графики распределения для датасета\n",
    "plt.xticks(rotation=45)  # Поворачиваем названия колонок на 45 градусов\n",
    "plt.tight_layout()  # Подгоняем элементы графика\n",
    "plt.show()  # Отображаем график"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. _Проведите разбиение на тренировочные и валидационные данные. Проведите необходимую предобработку данных для последующего обучения нейронной сети._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('defects', axis=1)  # Выделяем признаки\n",
    "y = train['defects']  # Выделяем целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение стандартизации к обучающему набору данных\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. _Реализуйте функцию, в которой вы будете определять архитектуру модели. Функция должна возвращать скомпилированную модель._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train, y_val = y_train.to_numpy(), y_val.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[AUC(name='roc_auc')]\n",
    "                  )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение весов классов\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. _Обучите модель нейронной сети (без использования методов регуляризации) на исходной тренировочной выборке (без добавления новых признаков). В процессе обучения нужно отслеживать метрику ROC_AUC на каждой эпохе, на валидационных данных._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "           validation_data=(X_val, y_val),\n",
    "           epochs=20,\n",
    "           batch_size=256,\n",
    "           class_weight={0:class_weights[0], 1:class_weights[1]})\n",
    "\n",
    "# Вычисляем предсказания вероятностей на тестовых данных\n",
    "test_pred_proba = model.predict(X_train)\n",
    "\n",
    "# Вычисляем ROC AUC с помощью roc_auc_score из sklearn\n",
    "roc_auc = roc_auc_score(y_train, test_pred_proba)\n",
    "\n",
    "# Выводим результат\n",
    "print(f'ROC AUC Score (sklearn): {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение значений лосса и валидационного лосса из истории\n",
    "def check_metrics(history, metric_name):\n",
    "    \"\"\"\n",
    "    Функция для проверки и визуализации метрик обучения.\n",
    "\n",
    "    Параметры:\n",
    "    - history: объект истории, возвращаемый методом fit()\n",
    "    - metric_name: название метрики для построения графика (например, 'loss', 'auc')\n",
    "\n",
    "    \"\"\"\n",
    "    # Получаем значения для заданной метрики\n",
    "    train_metrics = history.history[metric_name]\n",
    "    val_metrics = history.history[f'val_{metric_name}']\n",
    "\n",
    "    # Построение графика\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_metrics, label=f'Training {metric_name}', color='darkblue')\n",
    "    plt.plot(epochs, val_metrics, label=f'Validation {metric_name}', color='orange')\n",
    "    \n",
    "    # Настройка графика\n",
    "    plt.title(f'Training and Validation {metric_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Использование функции для построения графиков лосса и AUC\n",
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'roc_auc')  # Для метрики AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем вывод на основе графиков:\n",
    "\n",
    " Переобучение (Overfitting):\n",
    "   - Переобучение происходит, когда модель хорошо обучается на обучающих данных, но не может обобщать на валидационных данных. Это может привести к тому, что training loss снижается, в то время как validation loss начинает колебаться или даже увеличиваться. Модель \"запоминает\" особенности обучающего набора данных, но не может правильно обрабатывать новые данные.\n",
    "\n",
    " Шум в данных:\n",
    "   - Если в валидационном наборе данных есть шум или выбросы, это может вызвать колебания в validation loss. Обучающие данные могут быть более чистыми и упорядоченными, что приводит к более плавному снижению при обучении.\n",
    "\n",
    " Размер валидационного набора:\n",
    "   - Если размер вашего валидационного набора мал, колебания метрик на валидации могут быть более заметны, так как небольшие изменения в ошибках модели могут существенно повлиять на средние значения.\n",
    "\n",
    " Оптимизация гиперпараметров:\n",
    "   - Может понадобиться настройка гиперпараметров, таких как скорость обучения или регуляризация. Если скорость обучения слишком высока, это может привести к нестабильности в процессе оптимизации.\n",
    "\n",
    " Архитектура модели:\n",
    "   - Степень сложности модели может повлиять на способность обобщения. Слишком сложная модель может привести к переобучению, тогда как слишком простая может не обеспечить необходимую гибкость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. _Сгенерируйте новые признаки исходя из вашего EDA или наоборот — удалите ненужные признаки, которые препятствуют лучшему качеству модели при обучении._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_3.2.csv')\n",
    "# Переименуем названия столбцов в соответствии с PEP8\n",
    "df.columns = [re.sub('(?<!^)(?=[A-Z])|[ ]', '_', i, count=1).lower() for i in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем корреляцию между признаками и целевой переменной\n",
    "correlation_matrix = df.corr()\n",
    "correlation_with_target = correlation_matrix['defects']\n",
    "\n",
    "# Отображаем корреляцию с целевой переменной\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=correlation_with_target.index, y=correlation_with_target.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Correlation with Target Variable \"defects\"')\n",
    "plt.show()\n",
    "\n",
    "# Отбираем признаки с высокой корреляцией (например, > 0.1 или < -0.1)\n",
    "important_features = correlation_with_target[abs(correlation_with_target) > 0.1]\n",
    "print('Important Features:\\n', important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- данный метод не повлиял на улучшение значения метрики roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- добавим новые признаки в df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соотношение объема к сложности\n",
    "df['volume_to_difficulty'] = df['v'] / (df['d'] + 1e-10)  # Добавление малой константы для избежания деления на ноль\n",
    "# Описание: Соотношение объема к сложности, показывает эффективность \n",
    "\n",
    "# Индекс качества кода\n",
    "df['code_quality_index'] = (df['l_ocode'] + 0.5 * df['l_ocomment'] - 0.5 * df['l_oblank'])\n",
    "# Описание: Индекс качества кода, учитывает строки кода, комментарии и пустые строки\n",
    "\n",
    "# Общее количество уникальных операторов и операндов\n",
    "df['total_unique'] = df['uniq__op'] + df['uniq__opnd']\n",
    "# Описание: Общее количество уникальных операторов и операндов\n",
    "\n",
    "# Общее количество всех операторов и операндов\n",
    "df['total_operations'] = df['total__op'] + df['total__opnd']\n",
    "# Описание: Общее количество всех операторов и операндов\n",
    "\n",
    "# Соотношение ветвлений к количеству строк кода\n",
    "df['branch_to_code_ratio'] = df['branch_count'] / (df['loc'] + 1e-10)\n",
    "# Описание: Соотношение количества ветвлений к количеству строк кода, показывает сложность управления потоком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- данный метод создания новых признаков не помог улучшить результаты roc_auc в дальнейшем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитываем матрицу корреляции\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Настройка размера графика\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "# Построение тепловой карты\n",
    "sns.heatmap(\n",
    "    corr_matrix, \n",
    "    annot=True,      # Включаем аннотации\n",
    "    vmin=-1, \n",
    "    vmax=1, \n",
    "    center=0, \n",
    "    cmap='coolwarm', \n",
    "    linewidths=3,\n",
    "    linecolor='white', \n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Отображение графика\n",
    "plt.title('Корреляционная матрица', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Рассчитываем матрицу корреляции\n",
    "corr_matrix = df.corr().abs()  # Берем абсолютные значения корреляции\n",
    "\n",
    "# 2. Задаем порог для высоких корреляций\n",
    "threshold = 0.9  # Выберите значение порога, выше которого столбцы будут удалены\n",
    "\n",
    "# 3. Находим пары столбцов с высокой корреляцией\n",
    "to_drop = set()  # Создаем множество для хранения имен столбцов для удаления\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if corr_matrix.iloc[i, j] > threshold:  # Если корреляция выше порога\n",
    "            colname = corr_matrix.columns[i]  # Выберите имя столбца\n",
    "            to_drop.add(colname)\n",
    "\n",
    "# Удаляем столбцы с высокой корреляцией\n",
    "df_no_corr = df.drop(columns=to_drop)  # Обновленный DataFrame\n",
    "\n",
    "# Проверяем форму DataFrame после удаления столбцов\n",
    "print(\"Форма DataFrame после удаления столбцов с высокой корреляцией:\", df_no_corr.shape)\n",
    "\n",
    "# Если вам нужно увидеть, какие столбцы были удалены:\n",
    "print(\"Удаленные столбцы:\", to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- данный метод так же не помог улучшить результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Создаем списки границ для выбросов\n",
    "# lower_bounds = {}\n",
    "# upper_bounds = {}\n",
    "\n",
    "# # 5. Вычисляем границы для каждого числового признака\n",
    "# for feature in df_no_corr.select_dtypes(include=[np.number]).columns:  # Обрабатываем только числовые столбцы\n",
    "#     Q1 = df_no_corr[feature].quantile(0.25)\n",
    "#     Q3 = df_no_corr[feature].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "    \n",
    "#     # Устанавливаем границы для выбросов\n",
    "#     lower_bounds[feature] = Q1 - 1.5 * IQR\n",
    "#     upper_bounds[feature] = Q3 + 1.5 * IQR\n",
    "\n",
    "# # 6. Удаляем верхние выбросы из DataFrame\n",
    "# mask = np.ones(len(df_no_corr), dtype=bool)  # Изначально все записи считаем надежными\n",
    "# for feature in df_no_corr.select_dtypes(include=[np.number]).columns:\n",
    "#     # Удаляем только верхние выбросы\n",
    "#     mask &= (df_no_corr[feature] <= upper_bounds[feature])\n",
    "\n",
    "# df_no_outliers = df_no_corr[mask]\n",
    "\n",
    "# # Проверка размера данных до и после удаления выбросов\n",
    "# print(f\"Размер оригинального датасета: {df.shape[0]}\")\n",
    "# print(f\"Размер датасета после удаления выбросов: {df_no_outliers.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- данный метод ухудшил результат в следствии чего был \"закомменчен\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # 4. Создаем список границ для верхнего 5-процентного значений\n",
    "# upper_bounds = {}\n",
    "\n",
    "# # 5. Вычисляем 95-й процентиль для каждого числового признака\n",
    "# for feature in df_no_corr.select_dtypes(include=[np.number]).columns:  # Обрабатываем только числовые столбцы\n",
    "#     upper_bounds[feature] = df_no_corr[feature].quantile(0.95)\n",
    "\n",
    "# # 6. Удаляем верхние 5% из DataFrame\n",
    "# mask = np.ones(len(df_no_corr), dtype=bool)  # Изначально все записи считаем надежными\n",
    "# for feature in df_no_corr.select_dtypes(include=[np.number]).columns:\n",
    "#     # Сохраняем только те значения, которые меньше или равны 95-му процентилю\n",
    "#     mask &= (df_no_corr[feature] <= upper_bounds[feature])\n",
    "\n",
    "# df_no_outliers = df_no_corr[mask]\n",
    "\n",
    "# # Проверка размера данных до и после удаления верхних 5%\n",
    "# print(f\"Размер оригинального датасета: {df.shape[0]}\")\n",
    "# print(f\"Размер датасета после удаления верхних 5%: {df_no_outliers.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- данный метод так же ухудшил результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_corr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. _Переобучите модель на данных, которые представляют из себя новый датафрейм, и оцените, как изменилось качество модели (то есть вы либо добавили новые признаки, либо удалили старые, либо всё вместе). Исходя из этого примите решение, какие новые признаки хорошо повлияли на качество, а какие нет._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_no_corr.drop('defects', axis=1)  # Выделяем признаки\n",
    "target = df_no_corr['defects']  # Выделяем целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, stratify=target, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train, target_test = target_train.to_numpy(), target_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- код обучает модель Random Forest и оценивает важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель Random Forest\n",
    "model_rf = RandomForestClassifier(random_state=1)\n",
    "model_rf.fit(features_train, target_train)\n",
    "\n",
    "# Получаем важность признаков\n",
    "importances = model_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Печатаем важность признаков\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(features_train.shape[1]):\n",
    "    print(f\"{f + 1}. {features_train.columns[indices[f]]} ({importances[indices[f]]})\")\n",
    "\n",
    "# Визуализируем важность признаков\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(features_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(features_train.shape[1]), features_train.columns[indices], rotation=90)\n",
    "plt.xlim([-1, features_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование нового DataFrame с отобранными признаками\n",
    "selected_features = ['loc', 'id', 'e', 't', 'n', 'volume_to_difficulty', 'i', 'branch_to_code_ratio']\n",
    "df_selected = df[selected_features + ['defects']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- данный метод не помог улучшить результат val_roc_auc: она остается в районе 0.78, далее его рассматривать не буду (проверенно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from collections import Counter\n",
    "\n",
    "# # Проверка начального распределения классов\n",
    "# print(\"Original dataset shape:\", Counter(target_train))\n",
    "\n",
    "# # Применение SMOTE\n",
    "# smote = SMOTE(random_state=1)\n",
    "# X_resampled, y_resampled = smote.fit_resample(features_train, target_train)\n",
    "\n",
    "# # Проверка нового распределения классов\n",
    "# print(\"Resampled dataset shape:\", Counter(y_resampled))\n",
    "\n",
    "# # Стандартизация признаков\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Стандартизация обучающей выборки\n",
    "# features_train_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "# # Стандартизация тестовой выборки\n",
    "# features_test_scaled = scaler.transform(features_test)  # Замените 'y_resampled' на 'features_test'\n",
    "\n",
    "# # Теперь у вас будут стандартизированные признаки\n",
    "# print(\"Преобразованные признаки обучающей выборки:\")\n",
    "# print(features_train_scaled[:5])  # показать первые 5 строк\n",
    "# print(\"Преобразованные признаки тестовой выборки:\")\n",
    "# print(features_test_scaled[:5])    # показать первые 5 строк"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE помогает увеличить представление меньшинства путем создания новых синтетических образцов, что может уменьшить влияние дисбаланса классов. Однако для данной задачи данный метод регуляризации не помог улучшить результат для roc_auc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "# Стандартизация обучающей выборки\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "# Стандартизация тестовой выборки\n",
    "features_test = scaler.transform(features_test)\n",
    "\n",
    "print(\"Преобразованные признаки обучающей выборки:\")\n",
    "print(features_train[:2])  # показать первые 2 строки\n",
    "print(\"Преобразованные признаки тестовой выборки:\")\n",
    "print(features_test[:2])    # показать первые 2 строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "def generate_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=features_train.shape[1]))  # Рекомендуется использовать input_shape\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[AUC(name='roc_auc')]\n",
    "                  )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указываем классы как массив NumPy\n",
    "classes = np.array([False, True])\n",
    "\n",
    "# Вычисляем веса классов\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=target_train)\n",
    "\n",
    "# Преобразуем в словарь\n",
    "class_weight_dict = {False: class_weights[0], True: class_weights[1]}\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = generate_model()\n",
    "\n",
    "# Обучаем модель\n",
    "history = model.fit(features_train, target_train,\n",
    "                    validation_data=(features_test, target_test),\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    class_weight=class_weight_dict)\n",
    "\n",
    "# Вычисляем предсказания вероятностей на тестовых данных\n",
    "test_pred_proba = model.predict(features_test)\n",
    "\n",
    "# Вычисляем ROC AUC с помощью roc_auc_score из sklearn\n",
    "roc_auc = roc_auc_score(target_test, test_pred_proba)\n",
    "\n",
    "# Выводим результат\n",
    "print(f'ROC AUC Score (sklearn): {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение значений лосса и валидационного лосса из истории\n",
    "def check_metrics(history, metric_name):\n",
    "\n",
    "    # Получаем значения для заданной метрики\n",
    "    train_metrics = history.history[metric_name]\n",
    "    val_metrics = history.history[f'val_{metric_name}']\n",
    "\n",
    "    # Построение графика\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_metrics, label=f'Training {metric_name}', color='darkblue')\n",
    "    plt.plot(epochs, val_metrics, label=f'Validation {metric_name}', color='orange')\n",
    "    \n",
    "    # Настройка графика\n",
    "    plt.title(f'Training and Validation {metric_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Использование функции для построения графиков лосса и AUC\n",
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'roc_auc')  # Для метрики AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. _Собрав финальный датасет, который состоит из отфильтрованных (или добавленных) новых признаков, добавьте в вашу модель методы регуляризации — BatchNorm, Dropout, EarlyStopping, а также реализуйте автоматическое сохранение наилучших весов по метрике ROC_AUC на лучшей эпохе._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_corr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для генерации модели с добавлением Batch Normalization и Dropout\n",
    "def generate_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=features_train.shape[1]))\n",
    "    model.add(BatchNormalization())  # Добавляем Batch Normalization\n",
    "    model.add(Dropout(0.7))  # Добавляем Dropout с заданной вероятностью\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())  # Добавляем Batch Normalization\n",
    "    model.add(Dropout(0.6))  # Добавляем Dropout\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[AUC(name='roc_auc')]  # Используется для контроля процесса обучения\n",
    "                  )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Создаем модель\n",
    "model = generate_model()\n",
    "\n",
    "# Определяем колбэки для обучения\n",
    "early_stopping = EarlyStopping(monitor='val_roc_auc', patience=10, verbose=1, mode='max', restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_roc_auc', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Обучаем модель с колбэками\n",
    "history = model.fit(features_train, target_train,\n",
    "                    validation_data=(features_test, target_test),\n",
    "                    epochs=220,\n",
    "                    batch_size=128,\n",
    "                    class_weight=class_weight_dict,\n",
    "                    callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Вычисляем предсказания вероятностей на тестовых данных\n",
    "test_pred_proba = model.predict(features_test)\n",
    "\n",
    "# Вычисляем ROC AUC с помощью roc_auc_score из sklearn\n",
    "roc_auc = roc_auc_score(target_test, test_pred_proba)\n",
    "\n",
    "# Выводим результат\n",
    "print(f'ROC AUC Score (sklearn): {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение значений лосса и валидационного лосса из истории\n",
    "def check_metrics(history, metric_name):\n",
    "\n",
    "    # Получаем значения для заданной метрики\n",
    "    train_metrics = history.history[metric_name]\n",
    "    val_metrics = history.history[f'val_{metric_name}']\n",
    "\n",
    "    # Построение графика\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_metrics, label=f'Training {metric_name}', color='darkblue')\n",
    "    plt.plot(epochs, val_metrics, label=f'Validation {metric_name}', color='orange')\n",
    "    \n",
    "    # Настройка графика\n",
    "    plt.title(f'Training and Validation {metric_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Использование функции для построения графиков лосса и AUC\n",
    "check_metrics(history, 'loss')\n",
    "check_metrics(history, 'roc_auc')  # Для метрики AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. _Напишите вывод по всему проекту, он должен содержать в себе:_\n",
    "\n",
    "- Какие методы регуляризации улучшили качество, а какие плохо повлияли\n",
    "- Какие признаки повлияли на качество обучения (в лучшую сторону)\n",
    "- Наилучшую метрику ROC_AUC на валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: orange; font-weight: bold;\">Вывод по проекту</span>\n",
    "\n",
    "В ходе выполнения проекта по построению модели нейронной сети для решения задачи бинарной классификации были проведены обширные эксперименты, включающие выбор методов регуляризации и модификацию исходного набора данных. Далее представлены результаты и ключевые выводы из исследования.\n",
    "\n",
    "#### 1. Методы регуляризации\n",
    "\n",
    "В процессе обучения модели нейронной сети были рассмотрены следующие методы регуляризации:\n",
    "\n",
    "- SMOTE (Synthetic Minority Over-sampling Technique): Этот метод предназначен для увеличения представления класса меньшинства за счет создания новых синтетических образцов. Тем не менее, в данном случае применение SMOTE не привело к улучшению метрики ROC AUC, и результат остался на уровне 0.7902. Возможно, увеличение объема выборки меньшинства не оказало достаточно сильного влияния на качество модели.\n",
    "\n",
    "- Формирование нового DataFrame с отобранными признаками: Когда был создан DataFrame, содержащий только отборные признаки, не удалось улучшить результаты валидной метрики ROC AUC, которая осталась на уровне 0.78. Это указывает на то, что не все признаки в новом наборе данных оказывались информативными для поставленной задачи.\n",
    "\n",
    "- Создание границ для выбросов: Применение данного метода, включая вычисление границ для верхних 5% значений, также оказало негативное влияние на результат. Это может свидетельствовать о том, что удаление выбросов затронуло важную информацию в данных.\n",
    "\n",
    "- Вычисление границ для числовых признаков с использованием IQR (Interquartile Range): Этот метод также способствовал ухудшению качества модели, возможно из-за удаления полезных данными, которые могли бы улучшить предсказания.\n",
    "\n",
    "- Задание порога для высоких корреляций: Установка порога в 0.9 для удаления коррелирующих признаков не дала значительных улучшений. Это может указывать на то, что высококоррелированные признаки содержали ценную информацию, и их исключение снизило качество модели.\n",
    "\n",
    "\n",
    "#### 2. Влияние признаков на качество обучения\n",
    "\n",
    "В ходе экспериментов с генерацией и удалением признаков были выявлены следующие основные наблюдения:\n",
    "\n",
    "- Отрицательное влияние на качество обучения: Добавление новых признаков, основанных на EDA (Exploratory Data Analysis), не дало заметных улучшений в предсказательной способности модели. Линейно зависимые признаки или коррелирующие с другими признаками не добавили ценности. Удаление ненужных признаков (например, тех, которые имели низкое влияние на зависимую переменную или высокую корреляцию с другими признаками) также не смогло улучшить качество модели.\n",
    "\n",
    "- Единственное положительное влияние: Изменение параметра test_size в функции train_test_split с 0.2 на 0.3 стало одним из немногих позитивных изменений. Это увеличение размера тестовой выборки способствовало более надежной оценке модели на валидационных данных, что несколько улучшило стабильность и надежность оценок метрики ROC AUC.\n",
    "\n",
    "#### 3. Наилучшая метрика ROC AUC на валидации\n",
    "\n",
    "- Без регуляризации: Первоначально, при обучении модели на исходной тренировочной выборке без каких-либо методов регуляризации, была достигнута ROC AUC Score (sklearn): 0.7951.\n",
    "\n",
    "#### Заключение\n",
    "\n",
    "В целом, проект продемонстрировал значимость тщательного выбора методов регуляризации и обработки данных для достижения лучших результатов в машинном обучении. Методы, как SMOTE и различные подходы к работе с выбросами и коррелирующими признаками, не привели к ожидаемым улучшениям качества модели. Полученные результаты подчеркивают необходимость глубокого анализа и тестирования различных подходов в процессе подготовки данных и построения моделей, что может стать основой для будущих исследований и улучшений.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS создадим пайплайн и посмотрим score в df_selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предположим, ваша целевая переменная называется 'defects'\n",
    "X = df_selected.drop('defects', axis=1)\n",
    "y = df_selected['defects']\n",
    "\n",
    "# 1. Разделение данных на обучающую и тестовую выборки\n",
    "train_features, test_features, train_target, test_target = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 2. Установим предобработку с помощью ColumnTransformer (пример)\n",
    "numeric_features = train_features.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = train_features.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),  # Стандартизация числовых признаков\n",
    "        ('cat', OneHotEncoder(), categorical_features)  # Кодирование категориальных признаков\n",
    "    ])\n",
    "\n",
    "# 3. Создание полного пайплайна с SMOTE и классификаторами\n",
    "# Обратите внимание, что я добавил SMOTE из imblearn.pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),  # SMOTE теперь корректно добавлен\n",
    "    ('classify', LogisticRegression(class_weight='balanced', random_state=0))\n",
    "])\n",
    "\n",
    "# 4. Параметры для GridSearchCV\n",
    "params = [\n",
    "    {'classify': [LogisticRegression(class_weight='balanced', random_state=0)],\n",
    "     'classify__C': [0.01, 0.1, 1, 10, 100]},\n",
    "    {'classify': [DecisionTreeClassifier(class_weight='balanced', random_state=0)],\n",
    "     'classify__max_depth': [2, 5, 10, 20]},\n",
    "]\n",
    "\n",
    "# 5. Поиск лучших гиперпараметров на тренировочных данных\n",
    "grid_search = GridSearchCV(pipeline, param_grid=params, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X=train_features, y=train_target)\n",
    "\n",
    "# 6. Получаем информацию о наилучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# 7. Получаем предсказания меток классов и вероятностей на тестовых данных\n",
    "test_pred_proba = best_model.predict_proba(test_features)[:, 1]\n",
    "test_pred = best_model.predict(test_features)\n",
    "\n",
    "# 8. Оценка качества модели на тестовой выборке\n",
    "roc_auc = roc_auc_score(test_target, test_pred_proba)\n",
    "\n",
    "# 9. Выводим отчет о качестве классификации для лучшей модели\n",
    "print(\"Лучшие параметры модели:\")\n",
    "if isinstance(best_model.named_steps['classify'], LogisticRegression):\n",
    "    model_name = \"LogisticRegression\"\n",
    "    model_params = f\"Регуляризационный параметр модели: C = {best_params['classify__C']}\"\n",
    "elif isinstance(best_model.named_steps['classify'], DecisionTreeClassifier):\n",
    "    model_name = \"DecisionTreeClassifier\"\n",
    "    model_params = f\"max_depth = {best_params['classify__max_depth']}\"\n",
    "\n",
    "print(f\"Используемая модель: {model_name}\")\n",
    "print(model_params)\n",
    "\n",
    "# 10. Выводим отчет о качестве классификации\n",
    "print(\"\\nОтчет о качестве классификации:\")\n",
    "print(classification_report(test_target, test_pred))\n",
    "\n",
    "# 11. Вычисляем и выводим метрику ROC-AUC\n",
    "print(f\"\\nROC-AUC Score: {roc_auc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
